#!/usr/bin/env python3
import os
import sys
import glob
import math
import pickle
import warnings
from datetime import datetime

import numpy as np
import pandas as pd
import torch
import torch.nn as nn

warnings.filterwarnings("ignore")

from peptide_features import extract_features as extract_traditional_features

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CAMP_DIR = os.path.dirname(SCRIPT_DIR)  # CAMP_pytorch/

# ==================== TMC4 è›‹ç™½è´¨åºåˆ—ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰ ====================
TMC4_SEQUENCE = "MEENPTLESEAWGSSRGWLAPREARGAPCSSPGPSLSSVLNELPSAATLRYRDPGVLPWGALEEEEEDGGRSRKAFTEVTQTELQDPHPSRELPWPMQARRAHRQRNASRDQVVYGSGTKTDRWARLLRRSKEKTKEGLRSLQPWAWTLKRIGGQFGAGTESYFSLLRFLLLLNVLASVLMACMTLLPTWLGGAPPGPPGPDISSPCGSYNPHSQGLVTFATQLFNLLSGEGYLEWSPLFYGFYPPRPRLAVTYLCWAFAVGLICLLLILHRSVSGLKQTLLAESEALTSYSHRVFSAWDFGLCGDVHVRLRQRIILYELKVELEETVVRRQAAVRTLGQQARVWLVRVLLNLLVVALLGAAFYGVYWATGCTVELQEMPLVQELPLLKLGVNYLPSIFIAGVNFVLPPVFKLIAPLEGYTRSRQIVFILLRTVFLRLASLVVLLFSLWNQITCGGDSEAEDCKTCGYNYKQLPCWETVLGQEMYKLLLFDLLTVLAVALLIQFPRKLLCGLCPGALGRLAGTQEFQVPDEVLGLIYAQTVVWVGSFFCPLLPLLNTVKFLLLFYLKKLTLFSTCSPAARTFRASAANFFFPLVLLLGLAISSVPLLYSIFLIPPSKLCGPFRGQSSIWAQIPESISSLPETTQNFLFFLGTQAFAVPLLLISSILMAYTVALANSYGRLISELKRQRQTEAQNKVFLARRAVALTSTKPAL"
TMC4_SS = "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHCCCHHHHHHHCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHHHHHHHHHHHHHHHCCCCHHHHHHHHHHHCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHCCHHHHHCCCCHHHCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCHHHHHHHHHHHCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCHHHHHCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHCCCECCHHHHHHHHHHHHHHHHHHCCCCCCHHHHHHHHHHHHHHHHHHHHHHCCECCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCCCCCCCCCCCCCCCCCCHHHHHHHHCCHHHHHHHHHHHCHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHCCCC"


# ==================== CAMP æ¨¡å‹ç»„ä»¶ ====================

class GlobalMaxPool1d(nn.Module):
    def forward(self, x):
        output, _ = torch.max(x, 1)
        return output


class ConvNN(nn.Module):
    def __init__(self, in_dim, c_dim, kernel_size):
        super().__init__()
        self.convs = nn.Sequential(
            nn.Conv1d(in_dim, c_dim, kernel_size, padding="same"),
            nn.ReLU(),
            nn.Conv1d(c_dim, c_dim * 2, kernel_size, padding="same"),
            nn.ReLU(),
            nn.Conv1d(c_dim * 2, c_dim * 3, kernel_size, padding="same"),
            nn.ReLU(),
        )

    def forward(self, x):
        return self.convs(x)


class Self_Attention(nn.Module):
    def __init__(self, input_dim, dim_k, dim_v):
        super().__init__()
        self.q = nn.Linear(input_dim, dim_k)
        self.k = nn.Linear(input_dim, dim_k)
        self.v = nn.Linear(input_dim, dim_v)
        self._norm_fact = 1.0 / math.sqrt(dim_k)

    def forward(self, x):
        Q = self.q(x)
        K = self.k(x)
        V = self.v(x)
        atten = nn.Softmax(dim=-1)(torch.bmm(Q, K.permute(0, 2, 1))) * self._norm_fact
        return torch.bmm(atten, V)


class CAMP(nn.Module):
    """CAMP æ¨¡å‹ â€” å…±äº«åµŒå…¥å±‚ç‰ˆæœ¬"""

    def __init__(self):
        super().__init__()
        self.embed_seq = nn.Embedding(66, 128)
        self.embed_ss = nn.Embedding(76, 128)
        self.embed_two = nn.Embedding(8, 128)
        self.pep_convs = ConvNN(512, 64, 7)
        self.prot_convs = ConvNN(512, 64, 8)
        self.pep_fc = nn.Linear(3, 128)
        self.prot_fc = nn.Linear(23, 128)
        self.global_max_pooling = GlobalMaxPool1d()
        self.dnns = nn.Sequential(
            nn.Linear(640, 1024), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(1024, 512),
        )
        self.att = Self_Attention(128, 128, 128)
        self.output = nn.Linear(512, 1)

    def forward(self, *args, **kwargs):
        return self.extract_features(*args, **kwargs)

    def extract_features(self, x_pep, x_prot, x_pep_ss, x_prot_ss,
                         x_pep_2, x_prot_2, x_pep_dense, x_prot_dense):
        pep_seq_emb = self.embed_seq(x_pep.long())
        prot_seq_emb = self.embed_seq(x_prot.long())
        pep_ss_emb = self.embed_ss(x_pep_ss.long())
        prot_ss_emb = self.embed_ss(x_prot_ss.long())
        pep_2_emb = self.embed_two(x_pep_2.long())
        prot_2_emb = self.embed_two(x_prot_2.long())
        pep_dense = self.pep_fc(x_pep_dense)
        prot_dense = self.prot_fc(x_prot_dense)
        enc_pep = torch.cat([pep_seq_emb, pep_ss_emb, pep_2_emb, pep_dense], dim=-1)
        enc_prot = torch.cat([prot_seq_emb, prot_ss_emb, prot_2_emb, prot_dense], dim=-1)
        enc_pep = self.pep_convs(enc_pep.permute(0, 2, 1)).permute(0, 2, 1)
        enc_prot = self.prot_convs(enc_prot.permute(0, 2, 1)).permute(0, 2, 1)
        pep_cnn = self.global_max_pooling(enc_pep)
        prot_cnn = self.global_max_pooling(enc_prot)
        pep_att = self.global_max_pooling(self.att(self.embed_seq(x_pep.long())))
        prot_att = self.global_max_pooling(self.att(self.embed_seq(x_prot.long())))
        return pep_cnn, prot_cnn, pep_att, prot_att


# ==================== å®æ—¶ç‰¹å¾ç”Ÿæˆ ====================

AA_SET = {k: v for v, k in enumerate("ACBEDGFIHKMLONQPSRUTWVYXZ", 1)}
SS_SET = {"H": 1, "C": 2, "E": 3}
PHYSICO_SET = {
    'A': 1, 'C': 3, 'B': 7, 'E': 5, 'D': 5, 'G': 2, 'F': 1,
    'I': 1, 'H': 6, 'K': 6, 'M': 1, 'L': 1, 'O': 7, 'N': 4,
    'Q': 4, 'P': 1, 'S': 4, 'R': 6, 'U': 7, 'T': 4, 'W': 2,
    'V': 1, 'Y': 4, 'X': 7, 'Z': 7
}
SEQ_SS_DICT = {}
_idx = 1
for _aa in AA_SET:
    for _ss in SS_SET:
        SEQ_SS_DICT[f"{_aa}{_ss}"] = _idx
        _idx += 1

AA_PROPS = {
    'A': [1.28, 0.05, 1.00, 0.31, 6.11, 0.42, 0.23],
    'R': [2.34, 0.29, 6.13, -1.01, 10.74, 0.36, 0.25],
    'N': [1.60, 0.13, 2.95, -0.60, 6.52, 0.21, 0.22],
    'D': [1.60, 0.11, 2.78, -0.77, 2.98, 0.25, 0.20],
    'C': [1.77, 0.13, 2.43, 1.54, 6.35, 0.17, 0.41],
    'Q': [1.56, 0.18, 3.97, -0.22, 5.65, 0.36, 0.25],
    'E': [1.56, 0.15, 3.78, -0.64, 3.08, 0.44, 0.19],
    'G': [0.00, 0.00, 0.00, 0.00, 6.06, 0.13, 0.15],
    'H': [2.99, 0.23, 4.66, 0.13, 7.69, 0.27, 0.30],
    'I': [4.19, 0.19, 4.00, 1.80, 6.04, 0.30, 0.45],
    'L': [2.59, 0.19, 4.00, 1.70, 6.04, 0.39, 0.31],
    'K': [1.89, 0.22, 4.77, -0.99, 9.99, 0.32, 0.27],
    'M': [2.35, 0.22, 4.43, 1.23, 5.71, 0.38, 0.32],
    'F': [2.94, 0.29, 5.89, 1.79, 5.67, 0.30, 0.38],
    'P': [2.67, 0.00, 2.72, 0.72, 6.80, 0.13, 0.34],
    'S': [1.31, 0.06, 1.60, -0.04, 5.70, 0.20, 0.28],
    'T': [3.03, 0.11, 2.60, 0.26, 5.60, 0.21, 0.36],
    'W': [3.21, 0.41, 8.08, 2.25, 5.94, 0.32, 0.42],
    'Y': [2.94, 0.30, 6.47, 0.96, 5.63, 0.25, 0.41],
    'V': [3.67, 0.14, 3.00, 1.22, 6.02, 0.27, 0.49],
    'X': [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]
}

PAD_PEP = 50
PAD_PROT = 800


def _label_sequence(seq, pad_len):
    arr = np.zeros(pad_len, dtype=np.float64)
    for i, aa in enumerate(seq[:pad_len]):
        arr[i] = AA_SET.get(aa, 24)
    return arr


def _label_seq_ss(ss_str, pad_len, seq_str):
    arr = np.zeros(pad_len, dtype=np.float64)
    ss_clean = ss_str.replace(',', '')
    for i, (ss, aa) in enumerate(zip(ss_clean[:pad_len], seq_str[:pad_len])):
        arr[i] = SEQ_SS_DICT.get(f"{aa}{ss}", 0)
    return arr


def _label_physicochemical(seq, pad_len):
    arr = np.zeros(pad_len, dtype=np.float64)
    for i, aa in enumerate(seq[:pad_len]):
        arr[i] = PHYSICO_SET.get(aa, 7)
    return arr


def _get_dense_feature(sequence, pad_len, is_protein=False):
    feature_dim = 23 if is_protein else 3
    arr = np.zeros((pad_len, feature_dim), dtype=np.float64)
    for i, aa in enumerate(sequence[:pad_len]):
        props = AA_PROPS.get(aa, AA_PROPS['X'])
        if is_protein:
            arr[i, :7] = props
        else:
            arr[i, 0] = props[3]  # hydrophobicity
            arr[i, 1] = props[4]  # isoelectric
            arr[i, 2] = props[2]  # volume
    return arr


def generate_features_for_peptide(peptide_seq):
    """ä¸ºä»»æ„æ–°è‚½åºåˆ—å®æ—¶ç”Ÿæˆ CAMP æ‰€éœ€çš„å…¨éƒ¨ 8 ç§ç‰¹å¾ï¼ˆæ— éœ€é¢„è®¡ç®—å­—å…¸ï¼‰"""
    protein = TMC4_SEQUENCE
    prot_ss = ",".join(list(TMC4_SS))
    pep_ss = ",".join(["C"] * len(peptide_seq))

    return {
        "X_pep":       _label_sequence(peptide_seq, PAD_PEP),
        "X_prot":      _label_sequence(protein, PAD_PROT),
        "X_pep_ss":    _label_seq_ss(pep_ss, PAD_PEP, peptide_seq),
        "X_prot_ss":   _label_seq_ss(prot_ss, PAD_PROT, protein),
        "X_pep_2":     _label_physicochemical(peptide_seq, PAD_PEP),
        "X_prot_2":    _label_physicochemical(protein, PAD_PROT),
        "X_pep_dense": _get_dense_feature(peptide_seq, PAD_PEP, is_protein=False),
        "X_prot_dense": _get_dense_feature(protein, PAD_PROT, is_protein=True),
    }


# ==================== ç‰¹å¾å­—å…¸åŠ è½½ ==========================

def load_feature_dicts():
    """åŠ è½½ 8 ä¸ªç‰¹å¾å­—å…¸ï¼ˆå¯é€‰ï¼Œç¼ºå¤±æ—¶è¿”å› Noneï¼‰"""
    task, name = "cls", "peptide"
    keys_and_paths = {
        "prot_seq":   f"preprocess_v2_salty/{task}_{name}_protein_feature_dict",
        "pep_seq":    f"preprocess_v2_salty/{task}_{name}_peptide_feature_dict",
        "prot_ss":    f"preprocess_v2_salty/{task}_{name}_protein_ss_feature_dict",
        "pep_ss":     f"preprocess_v2_salty/{task}_{name}_compound_ss_feature_dict",
        "prot_dense": f"preprocess_v2_salty/{task}_{name}_protein_dense_feature_dict",
        "pep_dense":  f"preprocess_v2_salty/{task}_{name}_compound_dense_feature_dict",
        "prot_2":     f"preprocess_v2_salty/{task}_{name}_protein_2_feature_dict",
        "pep_2":      f"preprocess_v2_salty_/{task}_{name}_compound_2_feature_dict",
    }
    dicts = {}
    for key, rel_path in keys_and_paths.items():
        full = os.path.join(SCRIPT_DIR, rel_path)
        if not os.path.exists(full):
            print(f"  âš ï¸ ç‰¹å¾å­—å…¸ç¼ºå¤±ï¼Œå°†ä½¿ç”¨å®æ—¶ç”Ÿæˆæ¨¡å¼")
            return None
        with open(full, "rb") as f:
            dicts[key] = pickle.load(f, encoding="latin1")
    print(f"  âœ“ å·²åŠ è½½ï¼ˆå­—å…¸ä¸­æœ‰ {len(dicts.get('pep_seq', {}))} æ¡å·²çŸ¥åºåˆ—ï¼‰")
    return dicts


# ==================== åºåˆ— â†’ ç‰¹å¾å­—å…¸æ¡ç›® ====================

def prepare_sequence_features(peptide_seq, fd):
    """
    å°†ä¸€æ¡è‚½åºåˆ—è½¬æ¢ä¸º CAMP æ‰€éœ€çš„ 8 ç§ç‰¹å¾ã€‚
    ä¼˜å…ˆæŸ¥ç‰¹å¾å­—å…¸ï¼Œä¸åœ¨å­—å…¸ä¸­åˆ™å®æ—¶ç”Ÿæˆã€‚
    """
    # å°è¯•ä»å­—å…¸æŸ¥è¡¨
    protein = TMC4_SEQUENCE
    prot_ss = ",".join(list(TMC4_SS))
    pep_ss = ",".join(["C"] * len(peptide_seq))

    if fd and peptide_seq in fd.get("pep_seq", {}):
        arrays = {}
        arrays["X_prot"] = fd["prot_seq"][protein]
        arrays["X_prot_ss"] = fd["prot_ss"][prot_ss]
        arrays["X_prot_2"] = fd["prot_2"][protein]
        arrays["X_prot_dense"] = fd["prot_dense"][protein]
        arrays["X_pep"] = fd["pep_seq"][peptide_seq]
        arrays["X_pep_ss"] = fd["pep_ss"].get(pep_ss, _label_seq_ss(pep_ss, PAD_PEP, peptide_seq))
        arrays["X_pep_2"] = fd["pep_2"].get(peptide_seq, _label_physicochemical(peptide_seq, PAD_PEP))
        arrays["X_pep_dense"] = fd["pep_dense"].get(peptide_seq, _get_dense_feature(peptide_seq, PAD_PEP))
        return arrays

    # ä¸åœ¨å­—å…¸ä¸­ â†’ å®æ—¶ç”Ÿæˆå…¨éƒ¨ç‰¹å¾
    return generate_features_for_peptide(peptide_seq)


# ==================== CAMP ç‰¹å¾æå– ====================

def extract_camp_features_batch(models, batch_arrays, device):
    """ç”¨å¤šä¸ª CAMP æ¨¡å‹æå–ç‰¹å¾å¹¶å–å¹³å‡"""
    all_feats = []
    for model in models:
        model.eval()
        with torch.no_grad():
            tensors = {
                k: torch.from_numpy(v).float().to(device)
                for k, v in batch_arrays.items()
            }
            pep_cnn, prot_cnn, pep_att, prot_att = model.extract_features(
                tensors["X_pep"], tensors["X_prot"],
                tensors["X_pep_ss"], tensors["X_prot_ss"],
                tensors["X_pep_2"], tensors["X_prot_2"],
                tensors["X_pep_dense"], tensors["X_prot_dense"],
            )
            all_feats.append({
                "pep_cnn": pep_cnn.cpu().numpy(),
                "prot_cnn": prot_cnn.cpu().numpy(),
                "pep_att": pep_att.cpu().numpy(),
                "prot_att": prot_att.cpu().numpy(),
            })

    # å¹³å‡
    avg = {}
    for key in all_feats[0]:
        avg[key] = np.mean([f[key] for f in all_feats], axis=0)
    return avg


def build_interaction_features(feat):
    """ä¸è®­ç»ƒè„šæœ¬ä¸€è‡´çš„äº¤äº’ç‰¹å¾æ„é€ """
    pc, rc = feat["pep_cnn"], feat["prot_cnn"]
    pa, ra = feat["pep_att"], feat["prot_att"]

    cnn_concat = np.concatenate([pc, rc], axis=1)
    cnn_product = pc * rc
    cnn_diff = np.abs(pc - rc)
    pn = np.linalg.norm(pc, axis=1, keepdims=True) + 1e-8
    rn = np.linalg.norm(rc, axis=1, keepdims=True) + 1e-8
    cnn_cosine = np.sum(pc * rc, axis=1, keepdims=True) / (pn * rn)

    att_concat = np.concatenate([pa, ra], axis=1)
    att_product = pa * ra

    stats = np.concatenate([
        pc.mean(axis=1, keepdims=True),
        pc.std(axis=1, keepdims=True),
        rc.mean(axis=1, keepdims=True),
        rc.std(axis=1, keepdims=True),
    ], axis=1)

    return np.concatenate([
        cnn_concat, cnn_product, cnn_diff, cnn_cosine,
        att_concat, att_product, stats,
    ], axis=1)


# ==================== åŠ è½½ CAMP é¢„è®­ç»ƒæ¨¡å‹ ====================

def load_camp_models(device, num_models=5):
    """åŠ è½½ CAMP é¢„è®­ç»ƒæ¨¡å‹"""
    models = []
    for i in range(num_models):
        path = os.path.join(CAMP_DIR, f"model_full_ckpts_{i}.pkl")
        if not os.path.exists(path):
            continue
        model = CAMP()
        ckpt = torch.load(path, map_location=device, weights_only=False)
        state_dict = ckpt.get("model_state_dict", ckpt)
        model.load_state_dict(state_dict, strict=True)
        for p in model.parameters():
            p.requires_grad = False
        models.append(model.to(device).eval())
    return models


# ==================== ä¸»å‡½æ•° ====================

def main():
    print("=" * 60)
    print("å’¸å‘³è‚½é¢„æµ‹ â€” CAMP CNN + ML æ··åˆæ¨¡å‹")
    print("=" * 60)

    # --- è§£æå‚æ•° ---
    input_file = None
    model_path = None

    args = sys.argv[1:]
    i = 0
    while i < len(args):
        if args[i] == "--model" and i + 1 < len(args):
            model_path = args[i + 1]
            i += 2
        else:
            input_file = args[i]
            i += 1

    # --- æ‰¾è¾“å…¥æ–‡ä»¶ ---
    if input_file is None:
        for candidate in [ "æµ‹åºç»“æœ.xlsx","æµ‹åºç»“æœ_new.xlsx",
                          "salty_peptides_test.xlsx", "peptides.xlsx"]:
            if os.path.exists(os.path.join(SCRIPT_DIR, candidate)):
                input_file = os.path.join(SCRIPT_DIR, candidate)
                break
    if input_file and not os.path.isabs(input_file):
        input_file = os.path.join(SCRIPT_DIR, input_file)

    if input_file is None or not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶")
        print("   ç”¨æ³•: python predict_camp_ml_hybrid.py <è¾“å…¥æ–‡ä»¶.xlsx>")
        sys.exit(1)
    print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶: {os.path.basename(input_file)}")

    # --- æ‰¾æ¨¡å‹æ–‡ä»¶ ---
    if model_path is None:
        results_dir = os.path.join(SCRIPT_DIR, "camp_ml_results")
        candidates = sorted(glob.glob(os.path.join(results_dir, "camp_ml_hybrid_*.pkl")))
        if candidates:
            model_path = candidates[-1]  # æœ€æ–°çš„
    if model_path and not os.path.isabs(model_path):
        model_path = os.path.join(SCRIPT_DIR, model_path)

    if model_path is None or not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶")
        print("   è¯·å…ˆè¿è¡Œ train_camp_ml_hybrid.py è®­ç»ƒæ¨¡å‹")
        sys.exit(1)
    print(f"ğŸ“‚ æ¨¡å‹æ–‡ä»¶: {os.path.basename(model_path)}")

    # --- åŠ è½½ ML æ¨¡å‹ ---
    with open(model_path, "rb") as f:
        ckpt = pickle.load(f)
    ml_pipeline = ckpt["pipeline"]
    top_di = ckpt.get("top_dipeptides")
    top_tri = ckpt.get("top_tripeptides")
    top_cksaap = ckpt.get("top_cksaap")
    selected_indices = ckpt.get("selected_indices")
    threshold_mcc = ckpt.get("threshold_mcc", 0.5)
    threshold_f1 = ckpt.get("threshold_f1", 0.5)
    if selected_indices is not None:
        print(f"âœ… ML Pipeline å·²åŠ è½½ (ç‰¹å¾é€‰æ‹©: {len(selected_indices)} ç»´)")
    else:
        print(f"âœ… ML Pipeline å·²åŠ è½½ (æ— ç‰¹å¾é€‰æ‹©)")
    print(f"  é˜ˆå€¼: MCC={threshold_mcc:.3f}, F1={threshold_f1:.3f}")

    # --- è®¾å¤‡ ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # --- åŠ è½½ç‰¹å¾å­—å…¸ ---
    print("\nğŸ”„ åŠ è½½ç‰¹å¾å­—å…¸...")
    fd = load_feature_dicts()

    # --- åŠ è½½ CAMP æ¨¡å‹ ---
    print("ğŸ”„ åŠ è½½ CAMP é¢„è®­ç»ƒæ¨¡å‹...")
    camp_models = load_camp_models(device)
    print(f"  âœ“ ä½¿ç”¨ {len(camp_models)} ä¸ª CAMP æ¨¡å‹")

    # --- è¯»å–è¾“å…¥ ---
    print(f"\nğŸ“„ è¯»å–è¾“å…¥æ–‡ä»¶...")
    if input_file.endswith(".xlsx"):
        df = pd.read_excel(input_file)
    elif input_file.endswith(".csv"):
        df = pd.read_csv(input_file)
    else:
        df = pd.read_csv(input_file, sep="\t")

    # æ‰¾åºåˆ—åˆ—
    if "sequence" not in df.columns:
        for col in df.columns:
            if "seq" in col.lower() or "peptide" in col.lower():
                df["sequence"] = df[col]
                break
    if "sequence" not in df.columns:
        print(f"âŒ æ— æ³•æ‰¾åˆ°åºåˆ—åˆ—ï¼Œå½“å‰åˆ—: {list(df.columns)}")
        sys.exit(1)

    peptide_list = df["sequence"].tolist()
    print(f"   åŒ…å« {len(peptide_list)} æ¡åºåˆ—")

    # --- æå–ç‰¹å¾ & é¢„æµ‹ ---
    print("ğŸ”„ æå– CAMP CNN ç‰¹å¾å¹¶é¢„æµ‹...")
    valid_peptides = []
    all_X = []
    n_from_dict = 0
    n_generated = 0
    n_skipped = 0

    for pep in peptide_list:
        if not isinstance(pep, str) or not pep.strip():
            n_skipped += 1
            continue

        pep = pep.strip().upper()

        # ç»Ÿè®¡æ¥æº
        if fd and pep in fd.get("pep_seq", {}):
            n_from_dict += 1
        else:
            n_generated += 1

        feat_arrays = prepare_sequence_features(pep, fd)

        # CNN äº¤äº’ç‰¹å¾
        batch = {k: v[np.newaxis, ...] for k, v in feat_arrays.items()}
        raw_feat = extract_camp_features_batch(camp_models, batch, device)
        cnn_feat = build_interaction_features(raw_feat)[0]

        # ä¼ ç»Ÿåºåˆ—ç‰¹å¾
        trad_feat = extract_traditional_features(pep, top_di, top_tri, top_cksaap)

        # æ‹¼æ¥
        all_X.append(np.concatenate([cnn_feat, trad_feat]))
        valid_peptides.append(pep)

    if not valid_peptides:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆåºåˆ—å¯é¢„æµ‹")
        sys.exit(1)

    print(f"  âœ“ å­—å…¸æŸ¥è¡¨: {n_from_dict} æ¡, å®æ—¶ç”Ÿæˆ: {n_generated} æ¡, è·³è¿‡: {n_skipped} æ¡")

    X = np.array(all_X)

    # åº”ç”¨ç‰¹å¾é€‰æ‹©ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    if selected_indices is not None:
        X = X[:, selected_indices]
        print(f"  âœ“ ç‰¹å¾é€‰æ‹©: {all_X[0].shape[0]} â†’ {X.shape[1]} ç»´")

    probs = ml_pipeline.predict_proba(X)[:, 1]
    preds_default = ml_pipeline.predict(X)
    preds_mcc = (probs >= threshold_mcc).astype(int)
    preds_f1 = (probs >= threshold_f1).astype(int)

    # --- ç»“æœ ---
    results = pd.DataFrame({
        "sequence": valid_peptides,
        "Predicted_Score": probs,
        "Is_Salty_default": ["YES" if p == 1 else "NO" for p in preds_default],
        "Is_Salty_MCC": ["YES" if p == 1 else "NO" for p in preds_mcc],
        "Is_Salty_F1": ["YES" if p == 1 else "NO" for p in preds_f1],
    })
    results = results.sort_values("Predicted_Score", ascending=False)

    # ä¿å­˜
    results_dir = os.path.join(SCRIPT_DIR, "prediction_results")
    os.makedirs(results_dir, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(results_dir, f"camp_ml_hybrid_results_{ts}.csv")
    results.to_csv(output_file, index=False)

    print(f"\n{'='*60}")
    print(f"é¢„æµ‹å®Œæˆ! ç»“æœä¿å­˜è‡³: {output_file}")
    print(f"{'='*60}")

    n_default = int(preds_default.sum())
    n_mcc = int(preds_mcc.sum())
    n_f1 = int(preds_f1.sum())
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"  é»˜è®¤é˜ˆå€¼(0.5):   é¢„æµ‹ä¸ºå’¸å‘³ {n_default} / {len(probs)}")
    print(f"  MCCé˜ˆå€¼({threshold_mcc:.3f}): é¢„æµ‹ä¸ºå’¸å‘³ {n_mcc} / {len(probs)}")
    print(f"  F1é˜ˆå€¼({threshold_f1:.3f}):  é¢„æµ‹ä¸ºå’¸å‘³ {n_f1} / {len(probs)}")

    print(f"\nğŸ† é¢„æµ‹ç»“æœ (å‰20æ¡, ä½¿ç”¨MCCæœ€ä¼˜é˜ˆå€¼ {threshold_mcc:.3f}):")
    for i, (_, row) in enumerate(results.iterrows()):
        if i >= 20:
            print(f"   ... å…± {len(results)} æ¡ï¼Œå®Œæ•´ç»“æœè§ CSV æ–‡ä»¶")
            break
        status = "âœ…" if row["Is_Salty_MCC"] == "YES" else "âŒ"
        print(f"   {status} {row['sequence']:20} | åˆ†æ•°: {row['Predicted_Score']:.4f} | {row['Is_Salty_MCC']}")


if __name__ == "__main__":
    main()
